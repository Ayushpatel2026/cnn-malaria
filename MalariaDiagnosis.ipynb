{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9GJYX0+DJHXN3W5RKl9nM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushpatel2026/cnn-malaria/blob/main/MalariaDiagnosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ZFAQpqVM0GN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preparation**"
      ],
      "metadata": {
        "id": "zRv74iz-jEk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load the data set and its info\n",
        "dataset, dataset_info = tfds.load('malaria', with_info=True,\n",
        "                                  as_supervised=True,\n",
        "                                  shuffle_files=True,\n",
        "                                  split=['train'] )"
      ],
      "metadata": {
        "id": "HANyIKqUiwvG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset is of 27558 cell images\n",
        "# it is given as a dictionary with the keys 'image' and 'label'\n",
        "# each image is 103 by 103 pixels by 3 (for rgb)\n",
        "# it is not split already, we need to do that below\n",
        "# # let us look at the data\n",
        "for data in dataset[0].take(1):\n",
        "  print(data)"
      ],
      "metadata": {
        "id": "6lNiwqlEjDoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, train_ratio, val_ratio, test_ratio):\n",
        "  DATASET_SIZE = len(dataset)\n",
        "\n",
        "  # take from 0 to train_ratio*dataset_size\n",
        "  train_dataset = dataset.take(int(train_ratio*DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(train_ratio*DATASET_SIZE))\n",
        "\n",
        "  # after removing train, take val_ratio*dataset_size\n",
        "  val_dataset = val_test_dataset.take(int(val_ratio*DATASET_SIZE))\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(val_ratio*DATASET_SIZE))\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "oCIxta4sncIv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = split_dataset(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n"
      ],
      "metadata": {
        "id": "xmG94O6kmbcz"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}